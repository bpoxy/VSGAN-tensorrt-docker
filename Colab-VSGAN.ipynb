{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hpqbFInxrYdL"
      },
      "source": [
        "# Colab-VSGAN\n",
        "\n",
        "My repo: [styler00dollar/VSGAN-tensorrt-docker](https://github.com/styler00dollar/VSGAN-tensorrt-docker/)\n",
        "\n",
        "Since it was tried to keep things modular and save on install time, you need to pick on what to install yourself."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dfWp19tKePiR"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "50YNOoUCgcbM"
      },
      "outputs": [],
      "source": [
        "!nvcc --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hjfnge1eeR4C"
      },
      "outputs": [],
      "source": [
        "# check python version, for me its currently 3.10.12\n",
        "!python --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "4LVR-piSdQRT"
      },
      "outputs": [],
      "source": [
        "#@title Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title download all dependencies (~20min)\n",
        "#tensorrt\n",
        "%cd /content\n",
        "!sudo apt-get update\n",
        "!sudo apt-get install libnvinfer8 libnvonnxparsers8 libnvparsers8 libnvinfer-plugin8 libnvinfer-dev libnvonnxparsers-dev libnvparsers-dev libnvinfer-plugin-dev python3-libnvinfer tensorrt python3-libnvinfer-dev\n",
        "\n",
        "# precompiled\n",
        "%cd /content\n",
        "!sudo rm -rf /workspace\n",
        "!mkdir -p /workspace/tensorrt\n",
        "%cd /workspace/tensorrt\n",
        "!git clone https://github.com/styler00dollar/VSGAN-tensorrt-docker\n",
        "\n",
        "!mkdir vs_precompiled_colab\n",
        "%cd vs_precompiled_colab\n",
        "!wget https://github.com/styler00dollar/VSGAN-tensorrt-docker/releases/download/models/vs_precompiled_colab_py310.7z\n",
        "!7z x vs_precompiled_colab_py310.7z -O/content/vs_precompiled_colab_py310/\n",
        "\n",
        "!mkdir -p /usr/local/lib/vapoursynth/\n",
        "!mkdir -p /usr/local/lib/x86_64-linux-gnu/\n",
        "!mkdir -p /usr/local/lib/x86_64-linux-gnu/vapoursynth/\n",
        "!mkdir -p /usr/local/lib/python3.10/site-packages/\n",
        "\n",
        "!mv /content/vs_precompiled_colab_py310/vspipe /usr/local/bin/vspipe\n",
        "!mv /content/vs_precompiled_colab_py310/libwwxd.so /usr/local/lib/libwwxd.so\n",
        "!mv /content/vs_precompiled_colab_py310/libawarpsharp2.so /usr/local/lib/x86_64-linux-gnu/libawarpsharp2.so\n",
        "!mv /content/vs_precompiled_colab_py310/libfmtconv.so /usr/local/lib/libfmtconv.so\n",
        "!mv /content/vs_precompiled_colab_py310/libakarin.so /usr/local/lib/vapoursynth/libakarin.so\n",
        "!mv /content/vs_precompiled_colab_py310/libjulek.so /usr/local/lib/vapoursynth/libjulek.so\n",
        "!mv /content/vs_precompiled_colab_py310/librife.so /usr/local/lib/vapoursynth/librife.so\n",
        "!mv /content/vs_precompiled_colab_py310/libmvtools.so /usr/local/lib/libmvtools.so\n",
        "!mv /content/vs_precompiled_colab_py310/libdescale.so /usr/local/lib/vapoursynth/libdescale.so\n",
        "!mv /content/vs_precompiled_colab_py310/libvfrtocfr.so /usr/local/lib/x86_64-linux-gnu/vapoursynth/libvfrtocfr.so\n",
        "!mv /content/vs_precompiled_colab_py310/libvapoursynth.so /usr/local/lib/libvapoursynth.so\n",
        "!mv /content/vs_precompiled_colab_py310/libvapoursynth-script.so /usr/local/lib/libvapoursynth-script.so\n",
        "!mv /content/vs_precompiled_colab_py310/vapoursynth_dyn.so /usr/lib/python3.10/lib-dynload/vapoursynth.so\n",
        "!mv /content/vs_precompiled_colab_py310/vapoursynth.so /usr/local/lib/python3.10/site-packages/vapoursynth.so\n",
        "!mv /content/vs_precompiled_colab_py310/libzimg.so /usr/local/lib/libzimg.so\n",
        "!mv /content/vs_precompiled_colab_py310/libvstrt.so /usr/local/lib/libvstrt.so\n",
        "!mv /content/vs_precompiled_colab_py310/libmiscfilters.so /usr/local/lib/vapoursynth/libmiscfilters.so\n",
        "!mv /content/vs_precompiled_colab_py310/libvslsmashsource.so /usr/local/lib/vapoursynth/libvslsmashsource.so\n",
        "!mv /content/vs_precompiled_colab_py310/libvmaf_vs.so /usr/local/lib/vapoursynth/libvmaf.so\n",
        "!mv /content/vs_precompiled_colab_py310/libvmaf.so /usr/local/lib/x86_64-linux-gnu/libvmaf.so\n",
        "!mv /content/vs_precompiled_colab_py310/libbestsource.so /usr/local/lib/vapoursynth/libbestsource.so\n",
        "!mv /content/vs_precompiled_colab_py310/liblsmash.so.2 /usr/local/lib/liblsmash.so.2\n",
        "!mv /content/vs_precompiled_colab_py310/libvulkan.so /usr/lib/x86_64-linux-gnu/libvulkan.so\n",
        "\n",
        "!sudo ldconfig\n",
        "!chmod +x /usr/local/bin/vspipe\n",
        "\n",
        "# lsmash\n",
        "!sudo apt -y install libjansson-dev libzimg-dev nasm ninja-build\n",
        "!pip install ninja meson\n",
        "%cd /content\n",
        "!git clone https://code.videolan.org/videolan/dav1d/ && \\\n",
        "  cd dav1d && meson build --buildtype release --default-library static && ninja -C build install\n",
        "%cd /content\n",
        "# FFmpeg/FFmpeg: 40aa451154fc54b661036bfb90532199269397bc\n",
        "!git clone https://github.com/FFmpeg/FFmpeg && cd FFmpeg && \\\n",
        "  CFLAGS=-fPIC ./configure --enable-shared --disable-static --enable-pic --enable-gpl --enable-version3 --disable-programs --disable-doc --disable-avdevice \\\n",
        "  --disable-swresample --disable-postproc --disable-avfilter --disable-encoders --disable-muxers \\\n",
        "  --enable-libdav1d --disable-nvenc --disable-debug && \\\n",
        "  make -j$(nproc) && make install && ldconfig && cd /content && rm -rf FFmpeg\n",
        "\n",
        "# python\n",
        "!pip install numpy && pip install docutils pygments && pip install git+https://github.com/hahnec/color-matcher\n",
        "!pip install /content/vs_precompiled_colab_py310/*.whl kornia opencv-python pytorch-msssim thop einops timm wget mpgg vsutil \\\n",
        "  git+https://github.com/styler00dollar/vs-gmfss_union git+https://github.com/styler00dollar/vs-gmfss_fortuna git+https://github.com/styler00dollar/vs-dpir \\\n",
        "  scenedetect onnxruntime-gpu vsbasicvsrpp vsswinir https://github.com/pytorch/TensorRT/releases/download/v1.4.0/torch_tensorrt-1.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
        "!pip install torch-tensorrt-fx-only==1.5.0.dev0 && pip install nvidia-pyindex tensorrt==8.6.1 && pip install polygraphy\n",
        "\n",
        "# rife\n",
        "!sudo apt-get install libvulkan-dev libvulkan1 mesa-vulkan-drivers vulkan-tools -y\n",
        "!apt-get install libnvidia-gl-525 -y\n",
        "%cd /content\n",
        "!git clone https://github.com/styler00dollar/VapourSynth-RIFE-ncnn-Vulkan\n",
        "%cd VapourSynth-RIFE-ncnn-Vulkan\n",
        "!mv models /usr/local/lib/vapoursynth/\n",
        "\n",
        "# upgrading g++ and installing ffms2\n",
        "!sudo apt install build-essential manpages-dev software-properties-common ffmsindex libffms2-5 libffms2-dev -y\n",
        "!sudo add-apt-repository ppa:ubuntu-toolchain-r/test -y\n",
        "!sudo apt update -y && sudo apt install gcc-11 g++-11 -y\n",
        "!sudo update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-11 11\n",
        "!sudo update-alternatives --install /usr/bin/g++ g++ /usr/bin/g++-11 11\n",
        "\n",
        "# encoder\n",
        "!sudo apt install x264 x265 -y"
      ],
      "metadata": {
        "id": "k36bnZVq6eWo",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ED6eNarwobuR"
      },
      "source": [
        "# Render"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vy7HkJ6XOO3s"
      },
      "source": [
        "# Normal inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jSQxoSnXOJq0"
      },
      "outputs": [],
      "source": [
        "# if you want to use vs-mlrt, convert model into engine, some onnx are here: https://github.com/styler00dollar/VSGAN-tensorrt-docker/releases/tag/models\n",
        "# after creating the model, you can set the path in inference.py\n",
        "%cd /content\n",
        "!/usr/src/tensorrt/bin/trtexec --fp16 --onnx=model.onnx --minShapes=input:1x3x8x8 --optShapes=input:1x3x720x1280 --maxShapes=input:1x3x1080x1920 --saveEngine=/content/model.engine --tacticSources=+CUDNN,+CUBLAS,+CUBLAS_LT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eE1mgrLom8qI",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title inference.py\n",
        "%%writefile /workspace/tensorrt/VSGAN-tensorrt-docker/inference.py\n",
        "import sys\n",
        "\n",
        "sys.path.append(\"/workspace/tensorrt/VSGAN-tensorrt-docker/\")\n",
        "from inference_config import inference_clip\n",
        "\n",
        "video_path = \"/content/test.webm\"\n",
        "clip = inference_clip(video_path)\n",
        "clip.set_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rfFwJycObJ2I",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title inference_config.py\n",
        "%%writefile /workspace/tensorrt/VSGAN-tensorrt-docker/inference_config.py\n",
        "import sys\n",
        "import os\n",
        "\n",
        "sys.path.append(\"/workspace/tensorrt/VSGAN-tensorrt-docker/\")\n",
        "import vapoursynth as vs\n",
        "\n",
        "# video imports\n",
        "from src.vfi_inference import vfi_inference\n",
        "from src.vfi_model import video_model\n",
        "\n",
        "from src.rife import RIFE\n",
        "from src.IFRNet import IFRNet\n",
        "from src.GMFupSS import GMFupSS\n",
        "from src.GMFSS_union import GMFSS_union\n",
        "from vsgmfss_union import gmfss_union\n",
        "from src.eisai import EISAI\n",
        "from src.film import FILM\n",
        "from src.M2M import M2M\n",
        "from src.sepconv_enhanced import sepconv\n",
        "from src.IFUNet import IFUNet\n",
        "from src.stmfnet import STMFNet\n",
        "from src.rife_trt import rife_trt\n",
        "from src.cain_trt import cain_trt\n",
        "from src.GMFSS_Fortuna_union import GMFSS_Fortuna_union\n",
        "from src.GMFSS_Fortuna import GMFSS_Fortuna\n",
        "from vsgmfss_fortuna import gmfss_fortuna\n",
        "from vsdpir import dpir\n",
        "\n",
        "# upscale imports\n",
        "from vsbasicvsrpp import basicvsrpp\n",
        "from vsswinir import SwinIR\n",
        "\n",
        "from src.scene_detect import scene_detect\n",
        "\n",
        "from src.color_transfer import vs_color_match\n",
        "\n",
        "core = vs.core\n",
        "vs_api_below4 = vs.__api_version__.api_major < 4\n",
        "core = vs.core\n",
        "core.num_threads = 4  # can influence ram usage\n",
        "# only needed if you are inside docker\n",
        "core.std.LoadPlugin(path=\"/usr/lib/x86_64-linux-gnu/libffms2.so\")\n",
        "core.std.LoadPlugin(path=\"/usr/local/lib/libvstrt.so\")\n",
        "core.std.LoadPlugin(path=\"/usr/local/lib/x86_64-linux-gnu/libawarpsharp2.so\")\n",
        "\n",
        "\n",
        "def inference_clip(video_path=\"\", clip=None):\n",
        "    # ddfi is passing clip\n",
        "    if clip is None:\n",
        "        # cfr video\n",
        "        #clip = core.ffms2.Source(source=video_path, cache=False)\n",
        "        # vfr video\n",
        "        # clip = core.ffms2.Source(source=video_path, fpsnum = 24000, fpsden = 1001, cache=False)\n",
        "        # vfr video (automatically set num and den)\n",
        "        # clip = core.ffms2.Source(source=video_path, fpsnum = -1, fpsden = 1, cache=False)\n",
        "\n",
        "        # lsmash\n",
        "        clip = core.lsmas.LWLibavSource(source=video_path)\n",
        "        # lsmash with hw decoding preferred\n",
        "        # clip = core.lsmas.LWLibavSource(source=video_path, prefer_hw=3)\n",
        "\n",
        "        # resizing with descale\n",
        "        # Debilinear, Debicubic, Delanczos, Despline16, Despline36, Despline64, Descale\n",
        "        # clip = core.descale.Debilinear(clip, 1280, 720)\n",
        "\n",
        "    ###############################################\n",
        "    # SIMILARITY\n",
        "    # Set properties in clip for it to be applied\n",
        "    # SSIM for deduplication in frame interpolation\n",
        "\n",
        "    # offs1 = core.std.BlankClip(clip, length=1) + clip[:-1]\n",
        "    # offs1 = core.std.CopyFrameProps(offs1, clip)\n",
        "    # 0 = PSNR, 1 = PSNR-HVS, 2 = SSIM, 3 = MS-SSIM, 4 = CIEDE2000\n",
        "    # clip = core.vmaf.Metric(clip, offs1, 2)\n",
        "\n",
        "    # SCENE DETECT\n",
        "    # clip = core.misc.SCDetect(clip=clip, threshold=0.100)\n",
        "    # model based scene detect\n",
        "    # clip = scene_detect(clip, model_name=\"efficientnetv2_b0\", thresh=0.98, fp16=False)\n",
        "\n",
        "    # dedup (requires you to call \"vspipe parse.py -p .\" to generate infos_running.txt and tmp.txt)\n",
        "    # from src.dedup import get_dedup_frames\n",
        "    # frames_duplicated, frames_duplicating = get_dedup_frames()\n",
        "    # clip = core.std.DeleteFrames(clip, frames_duplicated)\n",
        "    # do upscaling here\n",
        "    # clip = core.std.DuplicateFrames(clip, frames_duplicating)\n",
        "    ###############################################\n",
        "    # COLORSPACE\n",
        "    ###############################################\n",
        "\n",
        "    # convert colorspace\n",
        "    clip = vs.core.resize.Bicubic(clip, format=vs.RGBS, matrix_in_s=\"709\")\n",
        "    # clip = vs.core.resize.Spline64(clip, format=vs.RGBS, matrix_in_s=\"709\", transfer_in_s=\"linear\")\n",
        "\n",
        "    # convert colorspace + resizing\n",
        "    # clip = vs.core.resize.Bicubic(\n",
        "    #    clip, width=1280, height=720, format=vs.RGBS, matrix_in_s=\"709\"\n",
        "    # )\n",
        "\n",
        "    ###############################################\n",
        "    # MODELS\n",
        "    ###############################################\n",
        "    # in rare cases it can happen that image range is not 0-1 and that resulting in big visual problems, clamp input\n",
        "    # clip = core.akarin.Expr(clip, \"x 0 1 clamp\")\n",
        "    # clip = clip.std.Expr(\"x 0 max 1 min\")\n",
        "    # clip = core.std.Limiter(clip, max=1, planes=[0,1,2])\n",
        "\n",
        "    ######\n",
        "    # VFI\n",
        "    ######\n",
        "\n",
        "    # VFI example for jit models\n",
        "    # clip = video_model(clip, fp16=False, model_path=\"/workspace/rvpV1_105661_G.pt\")\n",
        "\n",
        "    # Rife: model \"rife40\" up to \"rife46\" and \"sudo_rife4\"\n",
        "    # model_inference = RIFE(\n",
        "    #    scale=1, fastmode=True, ensemble=False, model_version=\"rife46\", fp16=True\n",
        "    # )\n",
        "\n",
        "    # IFRNet: model=\"small\" or \"large\"\n",
        "    # model_inference = IFRNet(model=\"small\", fp16=False)\n",
        "\n",
        "    # use gmfss_union instead for more speed\n",
        "    # model_inference = GMFupSS(partial_fp16=False)\n",
        "    # model_inference = GMFSS_union(partial_fp16=False)\n",
        "\n",
        "    # model_inference = EISAI() # 960x540\n",
        "\n",
        "    # FILM: model_choise=\"style\", \"l1\" or \"vgg\"\n",
        "    # model_inference = FILM(model_choise=\"vgg\")\n",
        "\n",
        "    # model_inference = M2M()\n",
        "\n",
        "    # model_inference = sepconv() # only 2x supported because architecture only outputs one image\n",
        "\n",
        "    # model_inference = IFUNet()\n",
        "\n",
        "    # model_inference = STMFNet()  # only 2x supported because architecture only outputs one image\n",
        "\n",
        "    # model_inference = GMFSS_Fortuna_union()\n",
        "\n",
        "    # model_inference = GMFSS_Fortuna()\n",
        "\n",
        "    # clip = vfi_inference(\n",
        "    #    model_inference=model_inference, clip=clip, multi=2, metric_thresh=0.999\n",
        "    # )\n",
        "\n",
        "    # clip = rife_trt(clip, multi = 2, scale = 1.0, device_id = 0, num_streams = 2, engine_path = \"/workspace/tensorrt/rife46.engine\")\n",
        "\n",
        "    # clip = cain_trt(clip, device_id = 0, num_streams = 4, engine_path = \"/workspace/tensorrt/rvp.engine\")\n",
        "\n",
        "    # clip = gmfss_union(clip, num_streams=4, trt=True, factor_num=2, ensemble=False, sc=True, trt_cache_path=\"/workspace/tensorrt/\")\n",
        "\n",
        "    # clip = gmfss_union(clip, num_streams=4, trt=True, factor_num=2, ensemble=False, sc=True, trt_cache_path=\"/workspace/tensorrt/\")\n",
        "\n",
        "    # more information here: https://github.com/HolyWu/vs-gmfss_fortuna/blob/master/vsgmfss_fortuna/__init__.py\n",
        "    # clip = gmfss_fortuna(clip, num_streams=4, trt=True, factor_num=2, factor_den=1, model=1, ensemble=False, sc=True, trt_cache_path=\"/workspace/tensorrt/\",)\n",
        "\n",
        "    ######\n",
        "    # UPSCALING WITH TENSORRT\n",
        "    ######\n",
        "    # vs-mlrt (you need to create the engine yourself, read the readme)\n",
        "    #clip = core.trt.Model(\n",
        "    #    clip,\n",
        "    #    engine_path=\"/content/model.engine\",\n",
        "    #    # tilesize=[854, 480],\n",
        "    #    overlap=[0, 0],\n",
        "    #    num_streams=2,\n",
        "    #)\n",
        "\n",
        "    # vs-mlrt (DPIR)\n",
        "    # DPIR does need an extra channel\n",
        "    # strength = 10.0\n",
        "    # noise_level = clip.std.BlankClip(format=vs.GRAYS, color=strength / 100)\n",
        "    # clip = core.trt.Model(\n",
        "    #    [clip, noise_level],\n",
        "    #    engine_path=\"dpir.engine\",\n",
        "    #    tilesize=[1280, 720],\n",
        "    #    num_streams=2,\n",
        "    # )\n",
        "\n",
        "    ######\n",
        "    # external vs plugins\n",
        "    ######\n",
        "\n",
        "    # BasicVSR++\n",
        "    # model list: https://github.com/HolyWu/vs-basicvsrpp/blob/0ad97ca908707d883922f092428337972a8d0215/vsbasicvsrpp/__init__.py#L42\n",
        "    # clip = basicvsrpp(clip, model = 1, length = 15, cpu_cache = False, tile_w = 0, tile_h = 0, tile_pad = 16)\n",
        "\n",
        "    # SwinIR\n",
        "    # clip = SwinIR(clip, task=\"lightweight_sr\", scale=2)\n",
        "\n",
        "    ###############################################\n",
        "    # ncnn (works in docker, but only on linux, because wsl on windows does not support vulkan)\n",
        "    ###############################################\n",
        "\n",
        "    # Rife ncnn (C++)\n",
        "    # Model list can be found in https://github.com/styler00dollar/VapourSynth-RIFE-ncnn-Vulkan\n",
        "    clip = core.misc.SCDetect(clip=clip, threshold=0.100)\n",
        "    clip = core.rife.RIFE(\n",
        "        clip,\n",
        "        model=9,\n",
        "        factor_num=2,\n",
        "        gpu_id=0,\n",
        "        gpu_thread=1,\n",
        "        tta=False,\n",
        "        uhd=False,\n",
        "        skip=True,\n",
        "        sc=True,\n",
        "    )\n",
        "\n",
        "    ######\n",
        "    # DDFI\n",
        "    # you need to use 8x interp for this\n",
        "    ######\n",
        "    # advanced example with pytorch vfi + dedup + scene change + upscaling\n",
        "\n",
        "    # offs1 = core.std.BlankClip(clip, length=1) + clip[:-1]\n",
        "    # offs1 = core.std.CopyFrameProps(offs1, clip)\n",
        "    # clip = core.vmaf.Metric(clip, offs1, 2)\n",
        "    # clip = core.resize.Bicubic(clip, width=1280, height=720, format=vs.RGBS, matrix_in=1)\n",
        "\n",
        "    # clip = core.misc.SCDetect(clip=clip, threshold=0.100)\n",
        "\n",
        "    # model_inference = GMFupSS(partial_fp16=True)\n",
        "    # clip = vfi_inference(\n",
        "    #     model_inference=model_inference, clip=clip, multi=8, metric_thresh=0.999\n",
        "    # )\n",
        "\n",
        "    # clip = vs.core.resize.Bicubic(clip, format=vs.YUV420P8, matrix_s=\"709\")\n",
        "    # offs1 = core.std.BlankClip(clip, length=1) + clip[:-1]\n",
        "    # offs1 = core.std.CopyFrameProps(offs1, clip)\n",
        "    # clip = core.vmaf.Metric(clip, offs1, 2)\n",
        "    # clip = vs.core.resize.Bicubic(clip, format=vs.RGBS, matrix_in_s=\"709\")\n",
        "\n",
        "    # clip = core.trt.Model(\n",
        "    #     clip,\n",
        "    #     engine_path=\"/content/model.engine\",\n",
        "    #     num_streams=3,\n",
        "    # )\n",
        "\n",
        "    ####\n",
        "    # Color Transfer\n",
        "    ####\n",
        "\n",
        "    # original_clip = clip\n",
        "    # original_clip = original_clip.resize.Spline16(format=vs.RGB24, matrix_in_s=\"470bg\")\n",
        "    # clip = clip.resize.Spline16(format=vs.RGB24, matrix_in_s=\"470bg\")\n",
        "    # clip = vs_color_match(clip, original_clip, method=\"mkl\")\n",
        "\n",
        "    ###\n",
        "    # Other\n",
        "    ###\n",
        "    # does not accept rgb clip, convert to yuv first\n",
        "    # clip = core.warp.AWarpSharp2(clip, thresh=128, blur=2, type=0, depth=[16, 8, 8], chroma=0, opt=True, planes=[0,1,2], cplace=\"mpeg1\")\n",
        "\n",
        "    # more information here: https://github.com/HolyWu/vs-dpir/blob/master/vsdpir/__init__.py\n",
        "    # clip = dpir(clip, num_streams = 4, nvfuser = False, cuda_graphs = False, trt = True, trt_cache_path = \"/workspace/tensorrt/\", task = \"deblock\", strength = 50, tile_w = 0, tile_h = 0, tile_pad= 8)\n",
        "\n",
        "    # clip = core.cas.CAS(clip, sharpness=0.5)\n",
        "\n",
        "    ###############################################\n",
        "    # OUTPUT\n",
        "    ###############################################\n",
        "    clip = vs.core.resize.Bicubic(clip, format=vs.YUV420P8, matrix_s=\"709\")\n",
        "    return clip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QOker8lwgE2r"
      },
      "outputs": [],
      "source": [
        "# default ubuntu ffmpeg (outdated ffmpeg)\n",
        "%cd /workspace/tensorrt/VSGAN-tensorrt-docker/\n",
        "!vspipe -c y4m inference.py - | ffmpeg -i pipe: /workspace/tensorrt/VSGAN-tensorrt-docker/example.mkv -y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FBc_O05UnJ_5"
      },
      "outputs": [],
      "source": [
        "%cd /workspace/tensorrt/VSGAN-tensorrt-docker/\n",
        "!vspipe -c y4m inference.py - | x264 - --demuxer y4m -o /workspace/tensorrt/VSGAN-tensorrt-docker/example.mkv -y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CY058j71oaNY"
      },
      "outputs": [],
      "source": [
        "%cd /workspace/tensorrt/VSGAN-tensorrt-docker/\n",
        "!vspipe -c y4m inference.py - | x265 - --y4m --crf 23 -o /workspace/tensorrt/VSGAN-tensorrt-docker/example.mkv -y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2nOmKlkiDgha"
      },
      "source": [
        "# Batch inference\n",
        "Also uses `inference_config.py` for configuration, but you also need to use `main.py` to iterate over files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "wQbtamr2DfvN"
      },
      "outputs": [],
      "source": [
        "#@title main.py\n",
        "%%writefile /workspace/tensorrt/VSGAN-tensorrt-docker/main.py\n",
        "import glob\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "input_dir = \"/workspace/tensorrt/input/\"\n",
        "tmp_dir = \"tmp/\"\n",
        "output_dir = \"/workspace/tensorrt/output/\"\n",
        "files = glob.glob(input_dir + \"/**/*.mkv\", recursive=True)\n",
        "files.sort()\n",
        "\n",
        "for f in files:\n",
        "    # creating folders if they dont exist\n",
        "    if not os.path.exists(tmp_dir):\n",
        "        os.mkdir(tmp_dir)\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.mkdir(output_dir)\n",
        "    if os.path.exists(tmp_dir):\n",
        "        shutil.rmtree(tmp_dir)\n",
        "        os.mkdir(tmp_dir)\n",
        "\n",
        "    # paths\n",
        "    out_render_path = os.path.join(\n",
        "        output_dir, os.path.splitext(os.path.basename(f))[0] + \"_rendered.mkv\"\n",
        "    )\n",
        "    mux_path = os.path.join(\n",
        "        output_dir, os.path.splitext(os.path.basename(f))[0] + \"_mux.mkv\"\n",
        "    )\n",
        "\n",
        "    # only needed for dedup\n",
        "    # os.system(f\"vspipe /workspace/tensorrt/parse.py --arg source='{f}' -p .\")\n",
        "\n",
        "    # os.system(f\"vspipe -c y4m inference_batch.py - | ffmpeg -i pipe: {out_render_path}\")\n",
        "    # os.system(\n",
        "    #    f\"ffmpeg -y -loglevel error -i '{f}' -i {out_render_path}  -map 1 -map 0 -map -0:v -codec copy -max_interleave_delta 0 '{mux_path}'\"\n",
        "    # )\n",
        "\n",
        "    ###### example presets ######\n",
        "    # speeds are resizised 4k footage with 7950x\n",
        "    # in terms of color banding:\n",
        "    # (less) x264 >  libx265 > libaom-av1 (with grain) > libsvtav1 > av1_nvenc (more)\n",
        "    # new encoders might result in smaller filesize/quality ratio, but there are banding problems which persist even with higher quality settings though\n",
        "    # in my personal opinion, stick with x264 for no banding and speed and aom for quality for filesize\n",
        "\n",
        "    ### slower ###\n",
        "    # x265 crf10 preset slow\n",
        "    # os.system(\n",
        "    #   f\"vspipe -c y4m inference_batch.py --arg source='{f}' - | ffmpeg -y -i '{f}' -thread_queue_size 100 -i pipe: -map 1 -map 0 -map -0:v -max_interleave_delta 0 -scodec copy -vcodec libx265 -crf 10 -preset slow '{mux_path}'\"\n",
        "    # )\n",
        "\n",
        "    # aom av1 (for quality/filesize but slow, encoder has banding issues without grain table)\n",
        "    # os.system(\n",
        "    #   f\"vspipe -c y4m inference_batch.py --arg source='{f}' - | ffmpeg -y -i '{f}' -thread_queue_size 100 -i pipe: -map 1 -map 0 -map -0:v -max_interleave_delta 0 -scodec copy -vcodec libaom-av1 -cpu-used 6 -lag-in-frames 48 -arnr-max-frames 4 -arnr-strength 1 -enable-cdef 1 -enable-restoration 0 -tune ssim -aom-params film-grain-table='/workspace/tensorrt/grain.tbl',input-depth=10,fp-mt=1,keyint=240 -crf 10 -tile-columns 1 -tile-rows 1 -row-mt 1 '{mux_path}'\"\n",
        "    # )\n",
        "\n",
        "    ### medium ###\n",
        "    # x265 crf10 default preset\n",
        "    # os.system(\n",
        "    #   f\"vspipe -c y4m inference_batch.py --arg source='{f}' - | ffmpeg -y -i '{f}' -thread_queue_size 100 -i pipe: -map 1 -map 0 -map -0:v -max_interleave_delta 0 -scodec copy -vcodec libx265 -crf 10 '{mux_path}'\"\n",
        "    # )\n",
        "\n",
        "    ### faster ###\n",
        "    # x264 crf10 default preset\n",
        "    # os.system(\n",
        "    #   f\"vspipe -c y4m inference_batch.py --arg source='{f}' - | ffmpeg -y -i '{f}' -thread_queue_size 100 -i pipe: -map 1 -map 0 -map -0:v -max_interleave_delta 0 -scodec copy -crf 10 '{mux_path}'\"\n",
        "    # )\n",
        "\n",
        "    # x264 crf10 preset slow\n",
        "    os.system(\n",
        "        f\"vspipe -c y4m inference_batch.py --arg source='{f}' - | ffmpeg -y -i '{f}' -thread_queue_size 100 -i pipe: -map 1 -map 0 -map -0:v -max_interleave_delta 0 -scodec copy -crf 10 -preset slow '{mux_path}'\"\n",
        "    )\n",
        "\n",
        "    # svt av1 (encoder has banding issues)\n",
        "    # os.system(\n",
        "    #   f\"vspipe -c y4m inference_batch.py --arg source='{f}' - | ffmpeg -y -i '{f}' -thread_queue_size 100 -i pipe: -map 1 -map 0 -map -0:v -max_interleave_delta 0 -scodec copy -vcodec libsvtav1 -svtav1-params tune=0,enable-overlays=1,enable-qm=1 -preset 8 -crf 10 '{mux_path}'\"\n",
        "    # )\n",
        "\n",
        "    # os.system(\n",
        "    #   f\"vspipe -c y4m inference_batch.py --arg source='{f}' - | ffmpeg -y -i pipe: %05d.png\"\n",
        "    # )\n",
        "\n",
        "    # deleting temp files\n",
        "    # os.remove(txt_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YOo2WgRSDlsa"
      },
      "outputs": [],
      "source": [
        "%cd /workspace/tensorrt/VSGAN-tensorrt-docker\n",
        "!python main.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "td6gkuc1ONGx"
      },
      "source": [
        "# ddfi\n",
        "\n",
        "Auto dedup-duplication inference example (More information on what exactly is meant is in [Mr-Z-2697/ddfi-rife](https://github.com/Mr-Z-2697/ddfi-rife).) Also uses `inference_config.py` for configuration, but you also need to use `deduped_vfi.py` to iterate over files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "RbUC1bIRFh2d"
      },
      "outputs": [],
      "source": [
        "#@title parse.py\n",
        "%%writefile /workspace/tensorrt/VSGAN-tensorrt-docker/parse.py\n",
        "import vapoursynth as vs\n",
        "import os\n",
        "import functools\n",
        "\n",
        "core = vs.core\n",
        "core.num_threads = 4\n",
        "core.max_cache_size = 4096\n",
        "\n",
        "core.std.LoadPlugin(path=\"/usr/lib/x86_64-linux-gnu/libffms2.so\")\n",
        "core.std.LoadPlugin(path=\"/usr/local/lib/libfmtconv.so\")\n",
        "core.std.LoadPlugin(path=\"/usr/local/lib/libmvtools.so\")\n",
        "\n",
        "# https://github.com/xyx98/my-vapoursynth-script/blob/master/xvs.py\n",
        "def props2csv(\n",
        "    clip: vs.VideoNode,\n",
        "    props: list,\n",
        "    titles: list,\n",
        "    output=\"info.csv\",\n",
        "    sep=\"\\t\",\n",
        "    charset=\"utf-8\",\n",
        "    tostring=None,\n",
        "):\n",
        "    file = open(output, \"w\", encoding=charset)\n",
        "    file.write(sep.join([\"n\"] + titles))\n",
        "    tostring = (\n",
        "        tostring\n",
        "        if callable(tostring)\n",
        "        else lambda x: x.decode(\"utf-8\")\n",
        "        if isinstance(x, bytes)\n",
        "        else str(x)\n",
        "    )\n",
        "\n",
        "    def tocsv(n, f, clip):\n",
        "        file.write(\n",
        "            \"\\n\"\n",
        "            + sep.join(\n",
        "                [str(n)]\n",
        "                + [tostring(eval(\"f.props.\" + i, globals(), {\"f\": f})) for i in props]\n",
        "            )\n",
        "        )\n",
        "\n",
        "        return clip\n",
        "        file.close()\n",
        "\n",
        "    return core.std.FrameEval(clip, functools.partial(tocsv, clip=clip), prop_src=clip)\n",
        "\n",
        "\n",
        "clip = core.ffms2.Source(globals()[\"source\"], cache=False)\n",
        "offs1 = core.std.BlankClip(clip, length=1) + clip[:-1]\n",
        "offs1 = core.std.CopyFrameProps(offs1, clip)\n",
        "offs1 = core.vmaf.Metric(clip, offs1, 2)\n",
        "offs1 = core.std.MakeDiff(offs1, clip)\n",
        "offs1 = core.fmtc.bitdepth(offs1, bits=16)\n",
        "offs1 = core.std.Expr(offs1, \"x 32768 - abs\")\n",
        "offs1 = core.std.PlaneStats(offs1)\n",
        "offs1 = props2csv(\n",
        "    offs1,\n",
        "    props=[\"_AbsoluteTime\", \"float_ssim\", \"PlaneStatsMax\"],\n",
        "    output=os.path.join(tmp_dir, \"infos_running.txt\"),\n",
        "    titles=[],\n",
        ")\n",
        "offs1.set_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "xRMLV98BORGn"
      },
      "outputs": [],
      "source": [
        "#@title ddfi.py\n",
        "#@markdown edit this file to customize interpolation\n",
        "%%writefile /workspace/tensorrt/VSGAN-tensorrt-docker/ddfi.py\n",
        "import sys\n",
        "sys.path.append(\"/workspace/tensorrt/VSGAN-tensorrt-docker/\")\n",
        "import vapoursynth as vs\n",
        "import os\n",
        "from src.rife import RIFE\n",
        "from src.IFRNet import IFRNet\n",
        "from src.GMFupSS import GMFupSS\n",
        "from src.eisai import EISAI\n",
        "from src.film import FILM\n",
        "from src.vfi_inference import vfi_inference\n",
        "\n",
        "core = vs.core\n",
        "\n",
        "core.std.LoadPlugin(path=\"/usr/lib/x86_64-linux-gnu/libffms2.so\")\n",
        "core.std.LoadPlugin(path=\"/usr/local/lib/libmvtools.so\")\n",
        "core.std.LoadPlugin(path=\"/usr/local/lib/libvstrt.so\")\n",
        "\n",
        "\n",
        "ssimt = 0.999\n",
        "pxdifft = 10240\n",
        "consecutivet = 2\n",
        "core.num_threads = 4\n",
        "core.max_cache_size = 4096\n",
        "\n",
        "tmp_dir = \"tmp/\"\n",
        "\n",
        "# frames to delete\n",
        "def processInfo():\n",
        "    with open(os.path.join(tmp_dir, \"infos_running.txt\"), \"r\") as f:\n",
        "        lines = [i.split(\"\\t\") for i in f][1:]\n",
        "    for i in range(len(lines)):\n",
        "        lines[i][0] = int(lines[i][0])\n",
        "        lines[i][1] = int(float(lines[i][1]) * 1000)\n",
        "        lines[i][2] = float(lines[i][2])\n",
        "        lines[i][3] = int(lines[i][3])\n",
        "    lines.sort()\n",
        "    startpts = lines[0][1]\n",
        "    consecutive = 0\n",
        "\n",
        "    dels = []\n",
        "    tsv2o = []\n",
        "    for i in range(len(lines)):\n",
        "        l = lines[i]\n",
        "        if l[2] >= ssimt and l[3] <= pxdifft and consecutive < consecutivet:\n",
        "            consecutive += 1\n",
        "            dels.append(l[0])\n",
        "        else:\n",
        "            consecutive = 0\n",
        "            tsv2o.append(l[1] - startpts)\n",
        "    return dels, tsv2o\n",
        "\n",
        "\n",
        "def newTSgen(tsv2o):\n",
        "    ts_new = list()\n",
        "    outfile = open(os.path.join(tmp_dir, \"tsv2nX8.txt\"), \"w\", encoding=\"utf-8\")\n",
        "    ts_o = [i for i in tsv2o][1:]\n",
        "\n",
        "    for x in range(len(ts_o) - 1):\n",
        "        ts_new.append(str(float(ts_o[x])))\n",
        "        for i in range(1, 8):\n",
        "            ts_new.append(\n",
        "                str(float(ts_o[x]) + (float(ts_o[x + 1]) - float(ts_o[x])) / 8 * i)\n",
        "            )\n",
        "    print(\"#timestamp format v2\", file=outfile)\n",
        "    for x in range(len(ts_new)):\n",
        "        print(ts_new[x], file=outfile)\n",
        "    print(ts_o[len(ts_o) - 1], file=outfile)\n",
        "    outfile.close()\n",
        "\n",
        "\n",
        "dels, tsv2o = processInfo()\n",
        "newTSgen(tsv2o)\n",
        "\n",
        "with open(os.path.join(tmp_dir, \"tmp.txt\")) as f:\n",
        "    video_path = f.readlines()[0]\n",
        "clip = core.ffms2.Source(video_path)\n",
        "clip = core.std.DeleteFrames(clip, dels)\n",
        "sup = core.mv.Super(clip, pel=1, levels=1)\n",
        "bw = core.mv.Analyse(sup, isb=True, levels=1, truemotion=False)\n",
        "clip = core.mv.SCDetection(clip, bw, thscd1=200, thscd2=85)\n",
        "\n",
        "\n",
        "# easy example with ncnn rife\n",
        "clip = core.resize.Bicubic(clip, format=vs.RGBS, matrix_in=1)\n",
        "clip = core.misc.SCDetect(clip=clip, threshold=0.100)\n",
        "clip = core.rife.RIFE(clip, model=9, sc=True, skip=True, multiplier=8)\n",
        "\n",
        "# example for custom vfi\n",
        "\"\"\"\n",
        "clip = core.resize.Bicubic(clip, format=vs.RGBS, matrix_in=1)\n",
        "\n",
        "model_inference = RIFE(\n",
        "    scale=1, fastmode=False, ensemble=True, model_version=\"rife46\", fp16=False\n",
        ")\n",
        "# model_inference = IFRNet(model=\"small\", fp16=False)\n",
        "# model_inference = GMFupSS()\n",
        "# model_inference = EISAI() # 960x540\n",
        "# model_inference = FILM(model_choise=\"vgg\")\n",
        "clip = vfi_inference(\n",
        "    model_inference=model_inference, clip=clip, multi=8\n",
        ")\n",
        "\"\"\"\n",
        "\n",
        "# advanced example with pytorch vfi + dedup + scene change + upscaling\n",
        "\"\"\"\n",
        "offs1 = core.std.BlankClip(clip, length=1) + clip[:-1]\n",
        "offs1 = core.std.CopyFrameProps(offs1, clip)\n",
        "clip = core.vmaf.Metric(clip, offs1, 2)\n",
        "clip = core.resize.Bicubic(clip, width=1280, height=720, format=vs.RGBS, matrix_in=1)\n",
        "\n",
        "clip = core.misc.SCDetect(clip=clip, threshold=0.100)\n",
        "\n",
        "model_inference = GMFupSS(partial_fp16=True)\n",
        "clip = vfi_inference(\n",
        "    model_inference=model_inference, clip=clip, multi=8\n",
        ")\n",
        "\n",
        "clip = vs.core.resize.Bicubic(clip, format=vs.YUV420P8, matrix_s=\"709\")\n",
        "offs1 = core.std.BlankClip(clip, length=1) + clip[:-1]\n",
        "offs1 = core.std.CopyFrameProps(offs1, clip)\n",
        "clip = core.vmaf.Metric(clip, offs1, 2)\n",
        "clip = vs.core.resize.Bicubic(clip, format=vs.RGBS, matrix_in_s=\"709\")\n",
        "\n",
        "clip = core.trt.Model(\n",
        "    clip,\n",
        "    engine_path=\"/content/model.engine\",\n",
        "    num_streams=3,\n",
        ")\n",
        "\"\"\"\n",
        "#######################\n",
        "\n",
        "clip = core.resize.Bicubic(\n",
        "    clip, format=vs.YUV420P10, matrix=1, dither_type=\"error_diffusion\"\n",
        ")\n",
        "clip = core.vfrtocfr.VFRToCFR(\n",
        "    clip, os.path.join(tmp_dir, \"tsv2nX8.txt\"), 192000, 1001, True\n",
        ")  # 24fps * 8\n",
        "sup = core.mv.Super(clip)\n",
        "fw = core.mv.Analyse(sup)\n",
        "bw = core.mv.Analyse(sup, isb=True)\n",
        "clip = core.mv.FlowFPS(clip, sup, bw, fw, 60, 1)\n",
        "clip.set_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "xysVSWfzCzhk"
      },
      "outputs": [],
      "source": [
        "#@title deduped_vfi.py\n",
        "%%writefile /workspace/tensorrt/VSGAN-tensorrt-docker/deduped_vfi.py\n",
        "import glob\n",
        "import os\n",
        "\n",
        "input_dir = \"/workspace/tensorrt/VSGAN-tensorrt-docker/input/\"\n",
        "tmp_dir = \"tmp/\"\n",
        "output_dir = \"/workspace/tensorrt/VSGAN-tensorrt-docker/output/\"\n",
        "files = glob.glob(input_dir + \"/**/*.mkv\", recursive=True)\n",
        "files.sort()\n",
        "\n",
        "for f in files:\n",
        "    # creating folders if they dont exist\n",
        "    if os.path.exists(tmp_dir) == False:\n",
        "        os.mkdir(tmp_dir)\n",
        "    if os.path.exists(output_dir) == False:\n",
        "        os.mkdir(output_dir)\n",
        "\n",
        "    # paths\n",
        "    txt_path = os.path.join(tmp_dir, \"tmp.txt\")\n",
        "    out_render_path = os.path.join(\n",
        "        output_dir, os.path.splitext(os.path.basename(f))[0] + \"_rendered.mkv\"\n",
        "    )\n",
        "    mux_path = os.path.join(\n",
        "        output_dir, os.path.splitext(os.path.basename(f))[0] + \"_mux.mkv\"\n",
        "    )\n",
        "\n",
        "    # writing filepath into temp txt\n",
        "    # workaround to pass filename parameter\n",
        "    f_txt = open(txt_path, \"w\")\n",
        "    f_txt.write(str(f))\n",
        "    f_txt.close()\n",
        "\n",
        "    os.system(\"vspipe parse.py -p .\")\n",
        "    os.system(\n",
        "        f\"vspipe -c y4m ddfi.py - | ffmpeg -i pipe: -vcodec libsvtav1 -crf 20 {out_render_path}\"\n",
        "    )\n",
        "\n",
        "    os.system(\n",
        "        f\"ffmpeg -y -loglevel error -i {f} -i {out_render_path}  -map 1 -map 0 -map -0:v -codec copy -max_interleave_delta 0 {mux_path}\"\n",
        "    )\n",
        "\n",
        "    # deleting temp files\n",
        "    os.remove(txt_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "83z9ZpctOWjE"
      },
      "outputs": [],
      "source": [
        "%cd /workspace/tensorrt/VSGAN-tensorrt-docker/\n",
        "!python deduped_vfi.py"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.8"
    },
    "vscode": {
      "interpreter": {
        "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
